---
layout: post
title:  "笔记《CS224N Project Report: From Note2Vec to Chord2Vec》"
date:   2021-10-05 21:42:00 +0800
categories: 音乐论文笔记
typora-root-url: ..\assets\img\1005
---


这篇文章的主要目标为：基于*Skip-gram*和*sequence-to-sequence*模型，学习和弦的向量表示。

<br>

### 摘要

<br>

本文基于NLP领域著名的Skip-gram模型，探索类似的高质量和弦嵌入方法。Skip-gram模型可以将自然语言中的语句表示为携带丰富句法信息（syntactic）及语义信息（semantic）的向量表示。

本文介绍了三种基于NLP模型的和弦嵌入模型：

1. 基于条件无关假说的模型；
2. 释放条件无关假说的模型；
3. 引入sequence-to-sequence的模型。

实验表明，第三种模型显著优于其他模型。

<br>

### Introduction

<br>

首先，论文阐述了**NLP中word2vec模型引入音乐数据表示的可行性及理论依据**：Word2vec模型在NLP领域中已被证明可以处理多样的问题，尤其是sequence modelling。而根据前人的工作，sequence modelling可以被用于算法作曲，那么，高质量的和弦嵌入理论上可以帮助算法作曲的进步。由此，引出了本文的主要探索任务：对于符号音乐数据，是否有类似于word2vec的嵌入算法可以完成音乐的嵌入任务。

受到Skip-gram模型的启发，本文试图找到一种和弦表示方式，有助于预测与当前和弦在时间上相邻的和弦。在语言中，单独的字可以表示为“独热码”（one-hot），但是对于和弦来说，同一时间可能有多个音符同时发声，所以我们采用一种“多热码”（many-hot）来表示一个和弦。然而正如在语言中一样，这种随机的编码方式，对于和弦之间的相关信息所涉甚少。

<br>

### 预备知识：Skip-gram

<br>

#### 什么是word2vec？

以无监督的学习方式，学习文本的词向量表示，通过一个嵌入空间使得语义上相近的单词在该空间内的距离很近。

#### 模型

Word2Vec模型中，主要有Skip-Gram和CBOW两种。Skip-gram是给定input word来预测上下文，CBOW是给定上下文来预测input word。

**Skip-gram模型的两个步骤**：

第一步为基于训练数据建立模型，在这一步中我们实际需要的是学得的参数，例如隐层的权重矩阵（实际上就是我们试图去学习的word vectors），这一步也被称为“Fake task”。

第二步是通过模型获取嵌入词向量。

1. Fake task

   在这一步，我们要构建一个完整的神经网络：（例句：The dog barked at the mailman.）

   （1） 首先，选择句子中间的一个词作为输入词（dog）；

   （2） 定义一个参数*skip_window*，代表从当前输入词的一侧选取词的数量（若为2：['The', 'dog', 'barked', 'at']）;

   （3） 定义一个参数*num_skips*，代表从当前窗口中选取多少个不同的词作为输出词（若为2：可能为['dog', 'barked'], ['dog', 'the']）；

   （4） 神经网络基于这个训练数据输出一个概率分布，即我们词典中每个词是输出词的可能性，即每个词有多大可能性跟输入词同时出现。神经网络的结构如下图所示：

   ![network](/assets/img/0930/network.PNG)

2. 最终目标：学习隐层的权重矩阵，one-hot编码使得隐层权重矩阵成为一个查找表。竖向一列代表一个neuron，横向一行代表一个word的所有feature。

从直观上理解，如果两个不同的单词拥有非常相似的“上下文”（例如“cat”与“kitty”），则通过我们的模型训练，这两个单词的嵌入向量将会非常相似。

**如何高效训练**

1. 三个创新：

   （1） 把常见的词组作为单个word，例如“New York”；

   （2） 对高频次单词进行抽样：

   ​			训练原始文本中遇到的每一个单词，都有一定概率从文本中删除，概率与单词在文本中出现的频率有关。

   （3） 对优化目标采用“negative sampling”，每个训练样本的训练只会更新一小部分的模型权重，从而降低计算负担。

2. 抽样率：（即保留每个词的概率）

   抽样的目的是，对于像“the”这类的高频词，并不会给我们提供关于输入单词的更多语义信息，并且会产生大量的此类训练样本。

   在决定词语的抽样率时，会设置一个默认值为0.001的阈值，这个值越小意味着这个单词被保留下的几率越小。

   抽样率与单词出现的频率有关，随着单词出现的频率增高，它被采样保留的概率越来越小。

3. 负采样（negative sampling）：

   首先要定义positive word和negative word。negative word即我们期望输出为0的神经元节点，即不应该与我们输入的单词同时出现的单词，positive word即为应同时出现的单词。

   当使用负采样时，我们会选择negative word中的一小部分加上positive word进行权重更新。

   那么该如何选择negative word呢？

   使用“一元模型分布”。将每个单词赋予一个权重，代表单词出现的频次。出现频次越高的单词越容易被选择。

   C语言实现的负采样会产生一个unigram table，包含一亿个元素，单词负采样概率越高，在表中出现的次数越多。选择负采样样本时，会产生一个随机数，在表中找到相应序号的样本作为负采样单词。此时负采样概率越高的单词越容易被选择。

<br>

### 模型解释

<br>

#### 双线模型（Bilinear model）

此模型为Skip-gram处理many-hot任务的简单迁移。与Skip-gram中采用negative sampling不同，此模型将最后一层softmax layer改为了N个输出的sigmoid layer，以用于预测和弦中的每个音符。

其余的部分与skip-gram模型一致。唯一需要注意的是，这一模型有一个前提，即两个和弦之间的音符是条件无关的。这个模型的效果不会很好，因为实际上和弦之间的音符是很有关系的。

<br>

#### 自回归模型（Autoregressive model）

为了同时保证和弦之间的相关性和易处理性，这一模型受到**NADE**（the Neural Autoregressive Distribution Estimator）的启发，利用链式法则将和弦某个音符的分布概率表示为给定和弦**d**与之前音符的共同条件作用。（例如context chord中的第3个音符与given chord和context chord的第1、2个音符有关。）并且定义了一个新的scoring function。

其实在这里，我并不是非常理解这样的条件限制如何实现。至于保留了和弦的易处理性，我猜是因为保留了many-hot的这种编码模式。

<br>

#### Sequence-to-sequence 模型

Sequence-to-sequence模型的基本想法是，创建从一个序列到另一个序列的映射模型。此模型关注输入序列中的每一个元素，并且尝试序列性地预测输出序列的下一个元素。

Sequence-to-sequence模型可以将输入的任意长的序列映射到任意长的输出序列，使用的神经网络结构为**RNN编码-译码模型**（RNN Encoder-Decoder）。模型的具体细节为：输入的序列经过一个**LSTM编码器**（LSTM Encoder），映射到一个固定长度的向量（此向量为LSTM编码器的最终状态），然后另一个**LSTM译码器**（LSTM Decoder）被用于从此向量中提取出输出序列。编码器与译码器会同时训练，以达到预测准确率最大化。

为了利用此模型实现和弦嵌入的任务，我们不再将和弦看作二进制的指示向量，而是看作其组成音符的序列。即一个随机长度（所含音符的数目随机）的和弦 **c**，会被表示为一个有序的音符序列，且
$$
c_i \leq c_{i+1} \in \{1,2,...,N\}
$$
这里的大小关系可以理解为在字母表中出现的次序。实际上最重要的是要保持音符序号的一致性，即每次训练都需要给每个音符一致的序号表示，这样才能够进行有效的和弦表示。

为了学得和弦嵌入，我们训练一个sequence-to-sequence模型来预测与输入和弦时间上相邻的邻居和弦。在这里我们将所有和弦表示成一个音符序列，使用一个连接符 **ε** 表示一个和弦的结束符。例如输入和弦为（60，64，67），邻居和弦为（59）和（62，65，69），那么我们有（60，64，67）作为我们的输入序列【这里原文为（60，62，67），怀疑是原文的失误，因为此处理应是输入和弦的音符组成】，（59，ε，62，65，69，ε）作为输出序列，训练过程中映射得到的固定长度向量即为输入和弦的嵌入表示。

<br>

### 实验

<br>

这篇文章中的实验采用了5个不同复杂度的数据集：JSB Chorales、Nottingham、MuseData、Piano-midi.de、Mix。作者从同一时间上的音符数、音符跨度等方面介绍了数据集：polyphony为0~15，平均的同时发声音符为3.9个，音符覆盖了钢琴的全音域。本文还采用了一种**扩大训练数据的方法**：将每一个音符都移调整数个半音。

#### Baselines

除了之前提到的模型，本文还采用了**Random**和**Marginal**两个方法作为对照。**Random**方法是将每一个音符的预测准确率都置为0.5，**Marginal**方法是一种经验式的方法，基于音符在训练数据中出现的频率，估测音符的预测概率。

模型的细节主要介绍了如下方面：1. batch size（128）；2. optimizer（Adam，D=1024）；3. epoch（200）（而最终模型是在验证集上错误率最小的那个）；4.  模型的layer（multilayer LSTM with 2 layers of 512 hidden units each）；5. 为了接受任意长度的序列，使用了 **standard bucketing** 和 **padding** 的方法；6. 使用的库（Tensorflow）。

<br>

### 结果

<br>

结果表明，即使是基于条件无关的假设，简单的线性模型也会学得一些信息，取得优于经验模型的结果。而自回归模型取得的效果更好，说明和弦的音符之间确实不是彼此独立的。最后，**Seq2seq c2v** 模型在**average test set log likelihood**这项指标上取得了远好于其他模型的结果。

<br>

### 总结与未来工作

<br>

本文介绍了三种NLP模型引入和弦嵌入任务的方法，最终证明了 **Seq2seq** 方法远远优于简单的线性Skip-gram方法。

然而，在文本分类问题中，简单的结构可以达到与深度学习模型相媲美的准确度，但是训练与评估更加迅速。因此，未来的工作可以基于Skip-gram模型提出新的模型，并且抛开音符间的条件无关性。

另外，还可以向可视化的方向探索，或者改进现有模型，以处理一整块的完整音乐。

